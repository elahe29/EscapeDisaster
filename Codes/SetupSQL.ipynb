{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BUILD THE DATASET\n",
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres://elahe@localhost/event_db\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#In Python: Define a database name (event_db), and your username for your computer. \n",
    "dbname = 'event_db'\n",
    "username = 'elahe'#to run below commands PostgreSQL should be launched\n",
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgres://%s@localhost/%s'%('elahe','event_db'))\n",
    "print(engine.url)\n",
    "\n",
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    print 'creating ...'\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "con = None\n",
    "con = psycopg2.connect(database = 'event_db', user = 'elahe')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#List all the csv files inside the data_path directory\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "datapath ='Data/EventData'\n",
    "#isfile(join(data_path, f)) condition is to make sure it is only files not the directories inside the data_path\n",
    "#f.endswith('.csv') condition is to make sure it is csv files\n",
    "csvfiles = [f for f in listdir(datapath) if isfile(join(datapath, f)) and f.endswith('.csv')]\n",
    "print csvfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1951_table\n",
      "d1952_table\n",
      "d1953_table\n",
      "d1954_table\n",
      "d1955_table\n",
      "d1956_table\n",
      "d1957_table\n",
      "d1958_table\n",
      "d1959_table\n",
      "d1960_table\n",
      "d1961_table\n",
      "d1962_table\n",
      "d1963_table\n",
      "d1964_table\n",
      "d1965_table\n",
      "d1966_table\n",
      "d1967_table\n",
      "d1968_table\n",
      "d1969_table\n",
      "d1970_table\n",
      "d1971_table\n",
      "d1972_table\n",
      "d1973_table\n",
      "d1974_table\n",
      "d1975_table\n",
      "d1976_table\n",
      "d1977_table\n",
      "d1978_table\n",
      "d1979_table\n",
      "d1980_table\n",
      "d1981_table\n",
      "d1982_table\n",
      "d1983_table\n",
      "d1984_table\n",
      "d1985_table\n",
      "d1986_table\n",
      "d1987_table\n",
      "d1988_table\n",
      "d1989_table\n",
      "d1990_table\n",
      "d1991_table\n",
      "d1992_table\n",
      "d1993_table\n",
      "d1994_table\n",
      "d1995_table\n",
      "d1996_table\n",
      "d1997_table\n",
      "d1998_table\n",
      "d1999_table\n",
      "d2000_table\n",
      "d2001_table\n",
      "d2002_table\n",
      "d2003_table\n",
      "d2004_table\n",
      "d2005_table\n",
      "d2006_table\n",
      "d2007_table\n",
      "d2008_table\n",
      "d2009_table\n",
      "d2010_table\n",
      "d2011_table\n",
      "d2012_table\n",
      "d2013_table\n",
      "d2014_table\n",
      "d2015_table\n",
      "d2016_table\n",
      "d2017_table\n"
     ]
    }
   ],
   "source": [
    "#Run this to create table_names\n",
    "#change the names by replasing the 'StormEvents_details-ftp_V1.0_' by '' in all the files\n",
    "table_names=[]\n",
    "for num in range(1951,2018):\n",
    "    table_name = 'd%d_table'%num\n",
    "    #print table_name\n",
    "    table_names.append(table_name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Run this to actually read CSV files and write them to your database server\n",
    "for f in csvfiles:\n",
    "    database_name = f.replace('StormEvents_details-ftp_v1.0_','')\n",
    "    database_name = database_name.split(\"_c\")[0]\n",
    "    table_name = database_name+'_table'\n",
    "\n",
    "    # read a database from CSV and load it into a pandas dataframe\n",
    "    database_name = pd.DataFrame.from_csv(datapath+'/'+f)\n",
    "    database_name = database_name.rename(columns=lambda x: x.strip())\n",
    "    \n",
    "    print 'creating ... ' + table_name\n",
    "    ## insert data into database from Python (proof of concept - this won't be useful for big data, of course)\n",
    "    database_name.to_sql(table_name, engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 13)\n",
      "(272, 13)\n",
      "(492, 13)\n",
      "(609, 13)\n",
      "(1413, 13)\n",
      "(1703, 13)\n",
      "(2184, 13)\n",
      "(2213, 13)\n",
      "(1813, 13)\n",
      "(1945, 13)\n",
      "(2246, 13)\n",
      "(2389, 13)\n",
      "(1968, 13)\n",
      "(2348, 13)\n",
      "(2835, 13)\n",
      "(2388, 13)\n",
      "(2688, 13)\n",
      "(3312, 13)\n",
      "(2926, 13)\n",
      "(3215, 13)\n",
      "(3471, 13)\n",
      "(2168, 13)\n",
      "(4453, 13)\n",
      "(5375, 13)\n",
      "(4975, 13)\n",
      "(3768, 13)\n",
      "(3728, 13)\n",
      "(3657, 13)\n",
      "(4279, 13)\n",
      "(6136, 13)\n",
      "(4517, 13)\n",
      "(7126, 13)\n",
      "(8322, 13)\n",
      "(7335, 13)\n",
      "(7979, 13)\n",
      "(8725, 13)\n",
      "(7363, 13)\n",
      "(7257, 13)\n",
      "(10407, 13)\n",
      "(10945, 13)\n",
      "(12516, 13)\n",
      "(13534, 13)\n",
      "(8664, 13)\n",
      "(15627, 13)\n",
      "(20461, 13)\n",
      "(48561, 13)\n",
      "(41991, 13)\n",
      "(50973, 13)\n",
      "(46383, 13)\n",
      "(52007, 13)\n",
      "(48875, 13)\n",
      "(50936, 13)\n",
      "(52956, 13)\n",
      "(52409, 13)\n",
      "(53976, 13)\n",
      "(56400, 13)\n",
      "(59010, 13)\n",
      "(71189, 13)\n",
      "(57398, 13)\n",
      "(62804, 13)\n",
      "(79091, 13)\n",
      "(64503, 13)\n",
      "(59985, 13)\n",
      "(59462, 13)\n",
      "(57787, 13)\n",
      "(55955, 13)\n",
      "(28679, 13)\n",
      "(1443346, 13)\n",
      "(1012498, 14)\n",
      "  EVENT_TYPE MONTH_NAME        STATE  CZ_FIPS  STATE_FIPS     CZ_NAME  \\\n",
      "0    Tornado  September  MISSISSIPPI       87        28.0     LOWNDES   \n",
      "1    Tornado       June       KANSAS       63        20.0        GOVE   \n",
      "2    Tornado      March        TEXAS      225        48.0     HOUSTON   \n",
      "3    Tornado        May     OKLAHOMA       33        40.0      COTTON   \n",
      "4    Tornado       July     OKLAHOMA       73        40.0  KINGFISHER   \n",
      "\n",
      "   INJURIES_DIRECT  INJURIES_INDIRECT  DEATHS_DIRECT  DEATHS_INDIRECT  \\\n",
      "0                0                  0              0                0   \n",
      "1                0                  0              0                0   \n",
      "2                0                  0              0                0   \n",
      "3                0                  0              0                0   \n",
      "4                0                  0              0                0   \n",
      "\n",
      "  DAMAGE_PROPERTY DAMAGE_CROPS  YEAR  DAMAGE_ID  \n",
      "0              0K            0  1951          0  \n",
      "1              0K            0  1951          1  \n",
      "2            2.5K            0  1951          2  \n",
      "3            2.5K            0  1951          3  \n",
      "4            .25K            0  1951          4  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4ca2d388bf57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdamage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mdamage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'damage_table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1343\u001b[0m         sql.to_sql(self, name, con, flavor=flavor, schema=schema,\n\u001b[1;32m   1344\u001b[0m                    \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                    chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m    469\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[1;32m    470\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                       chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                          schema=schema, dtype=dtype)\n\u001b[1;32m   1150\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;31m# check for potentially case sensitivity issues (GH7815)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, chunksize)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mchunk_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m     def _query_iterator(self, result, chunksize, columns, coerce_float=True,\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36m_execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object, *multiparams, **params)\u001b[0m\n\u001b[1;32m    912\u001b[0m                 type(object))\n\u001b[1;32m    913\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/sqlalchemy/sql/elements.pyc\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moptionaldict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistilled_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m         )\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1114\u001b[0m                         \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                         \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m                         context)\n\u001b[0m\u001b[1;32m   1117\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/sqlalchemy/engine/default.pyc\u001b[0m in \u001b[0;36mdo_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_executemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# connect to dataset:\n",
    "#Read Damage information from all the tables\n",
    "\n",
    "damage_list = []\n",
    "#location_ids=[]\n",
    "cnt=0\n",
    "for table_name in table_names:\n",
    "    # query: \n",
    "    #for sql query you don't need to put column names into \"\" but if the column names are \n",
    "    #in UPPER CASE LETTERS you have to do that\n",
    "    \n",
    "    year = int(re.findall(r'\\d+', table_name)[0])\n",
    "    sql_query = \"\"\"\n",
    "    SELECT \"EVENT_TYPE\",\"MONTH_NAME\",\"STATE\",\"CZ_FIPS\",\"STATE_FIPS\",\"CZ_NAME\",\n",
    "    \"INJURIES_DIRECT\",\"INJURIES_INDIRECT\",\"DEATHS_DIRECT\",\"DEATHS_INDIRECT\",\n",
    "    \"DAMAGE_PROPERTY\",\"DAMAGE_CROPS\" FROM %s;\n",
    "\n",
    "    \"\"\" %table_name\n",
    "    #print sql_query\n",
    "    damage_sql = pd.read_sql_query(sql_query,con)\n",
    "\n",
    "    damage_sql['YEAR']=year\n",
    "    damage_list.append(damage_sql)\n",
    "    #cnt= cnt+1\n",
    "#print location\n",
    "damage_df =pd.concat(damage_list,axis=0)\n",
    "print damage_df.shape\n",
    "#location_df =pd.merge(location_list,how='left', left_on=['STATE','CZ_NAME'], right_on = ['STATE','CZ_NAME'])\n",
    "#location_df =reduce(lambda x, y: pd.merge(x, y,'outer'), location_list)\n",
    "#location_df =reduce(lambda x, y: pd.merge(x, y, on = ['STATE','CZ_NAME']), location_list)\n",
    "#df = reduce(lambda df1,df2: pd.merge(df1,df2,on='id'), dfList)\n",
    "#location_df.set_index('LOCATION_ID', inplace=True)\n",
    "damage_df = damage_df.drop_duplicates()\n",
    "damage_df['DAMAGE_ID'] = damage_df.index\n",
    "print damage_df.shape\n",
    "print damage_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "damage_df.to_sql('damage_table', engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some column names have spaces before and after their names so trim the names\n",
    "for table_name in table_names:\n",
    "    sql_query = \"\"\"ALTER TABLE %s RENAME <oldcolumn> TO <newcolumn>;\"\"\"% table_name\n",
    "    sql_query = \"\"\"UPDATE %s\n",
    "                    SET\n",
    "                ColumnName = LTRIM(RTRIM(ColumnName))\"\"\"% table_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to dataset:\n",
    "#Read Location information from all the tables\n",
    "\n",
    "location_list = []\n",
    "#location_ids=[]\n",
    "cnt=0\n",
    "for table_name in table_names:\n",
    "    # query: \n",
    "    #for sql query you don't need to put column names into \"\" but if the column names are \n",
    "    #in UPPER CASE LETTERS you have to do that\n",
    "    sql_query = \"\"\"\n",
    "    SELECT \"STATE\",\"CZ_FIPS\",\"STATE_FIPS\",\"CZ_TYPE\",\"CZ_NAME\",\"CZ_TIMEZONE\" FROM %s;\n",
    "    \"\"\" %table_name\n",
    "    #print sql_query\n",
    "    location_info_from_sql = pd.read_sql_query(sql_query,con)\n",
    "    #location_ids.append(cnt)\n",
    "    location_list.append(location_info_from_sql)\n",
    "    #cnt= cnt+1\n",
    "#print location\n",
    "location_df =pd.concat(location_list,axis=0)\n",
    "#location_df =pd.merge(location_list,how='left', left_on=['STATE','CZ_NAME'], right_on = ['STATE','CZ_NAME'])\n",
    "#location_df =reduce(lambda x, y: pd.merge(x, y,'outer'), location_list)\n",
    "#location_df =reduce(lambda x, y: pd.merge(x, y, on = ['STATE','CZ_NAME']), location_list)\n",
    "#df = reduce(lambda df1,df2: pd.merge(df1,df2,on='id'), dfList)\n",
    "#location_df.set_index('LOCATION_ID', inplace=True)\n",
    "location_df = location_df.drop_duplicates()\n",
    "location_df['LOCATION_ID'] = location_df.index\n",
    "\n",
    "print location_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the location_df to the sql-server\n",
    "#accordig to my analysis CZ_FIPS can be used as the main (unique key to the table)\n",
    "#it is also never null value\n",
    "location_df.to_sql('location_table', engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    EVENT_TYPE  EVENT_TYPE_ID\n",
      "0      Extreme Cold/Wind Chill              0\n",
      "1                        Flood              1\n",
      "2               Excessive Heat              2\n",
      "3                         Heat              3\n",
      "4                    Dense Fog              4\n",
      "5                   Waterspout              5\n",
      "6                  Rip Current              6\n",
      "7                    High Surf              7\n",
      "8                    High Wind              8\n",
      "9                    Ice Storm              9\n",
      "10                   Lightning             10\n",
      "11                     Drought             11\n",
      "12           Thunderstorm Wind             12\n",
      "13                        Hail             13\n",
      "14               Coastal Flood             14\n",
      "15                Winter Storm             15\n",
      "16                     Tornado             16\n",
      "17         Hurricane (Typhoon)             17\n",
      "18                    Blizzard             18\n",
      "19                Frost/Freeze             19\n",
      "20                    Wildfire             20\n",
      "21             Cold/Wind Chill             21\n",
      "22                  Dust Storm             22\n",
      "23                 Strong Wind             23\n",
      "24              Winter Weather             24\n",
      "25                 Debris Flow             25\n",
      "26                      Seiche             26\n",
      "27                  Heavy Snow             27\n",
      "28                Funnel Cloud             28\n",
      "29            Storm Surge/Tide             29\n",
      "..                         ...            ...\n",
      "31            Lake-Effect Snow             31\n",
      "32                Freezing Fog             32\n",
      "33                   Avalanche             33\n",
      "34                  Dust Devil             34\n",
      "35                       Sleet             35\n",
      "36              Tropical Storm             36\n",
      "37                  Heavy Rain             37\n",
      "38                Volcanic Ash             38\n",
      "39                       OTHER             39\n",
      "40             Northern Lights             40\n",
      "41                   High Snow             41\n",
      "42    Marine Thunderstorm Wind             42\n",
      "43                  Heavy Wind             43\n",
      "44                 Marine Hail             44\n",
      "45            Marine High Wind             45\n",
      "46                     Tsunami             46\n",
      "47                   Landslide             47\n",
      "48                 Dense Smoke             48\n",
      "49          Marine Strong Wind             49\n",
      "50             Lakeshore Flood             50\n",
      "51       Astronomical Low Tide             51\n",
      "52                   Hurricane             52\n",
      "53            Volcanic Ashfall             53\n",
      "54         Tropical Depression             54\n",
      "55            Marine Dense Fog             55\n",
      "56    Marine Hurricane/Typhoon             56\n",
      "57       Marine Tropical Storm             57\n",
      "58                 Sneakerwave             58\n",
      "59            Marine Lightning             59\n",
      "60  Marine Tropical Depression             60\n",
      "\n",
      "[61 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#connect to dataset:\n",
    "#Read event information from all the tables\n",
    "con = None\n",
    "con = psycopg2.connect(database = 'event_db', user = 'elahe')\n",
    "location_list = []\n",
    "#location_ids=[]\n",
    "cnt=0\n",
    "# get the table names after the year 2000 the reason is before that all the events are mostly tornado\n",
    "#later on if we decide to use all the tables it is better to normalize number of events base on the \n",
    "#previous years for the model not to be biased towards tornado\n",
    "\n",
    "#use a regexp to get the numbers out of string\n",
    "import re\n",
    "event_type_list = []\n",
    "for table_name in table_names:\n",
    "    #event_type_year = pd.DataFrame(columns = ['EVENT_TYPE','TYPE_ID'])\n",
    "    event_type_year = pd.DataFrame(columns = ['EVENT_TYPE'])\n",
    "    year = int(re.findall(r'\\d+', table_name)[0])\n",
    "    if year >=2000:\n",
    "        # query: \n",
    "        #for sql query you don't need to put column names into \"\" but if the column names are \n",
    "        #in UPPER CASE LETTERS you have to do that\n",
    "        sql_query = \"\"\"\n",
    "        select distinct \"EVENT_TYPE\" FROM %s;\n",
    "        \"\"\" %table_name\n",
    "        #print sql_query\n",
    "        event_type_from_sql = pd.read_sql_query(sql_query,con)\n",
    "        event_type_year['EVENT_TYPE']=event_type_from_sql['EVENT_TYPE']\n",
    "        #event_type_year['TYPE_ID']=event_type_from_sql.index\n",
    "        #print event_type_year.head()\n",
    "        event_type_list.append(event_type_year)\n",
    "event_type_df =reduce(lambda df1,df2: pd.merge(df1,df2,on='EVENT_TYPE',how='outer'), event_type_list)\n",
    "event_type_df['EVENT_TYPE_ID'] = event_type_df.index\n",
    "print event_type_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#connect to dataset:\n",
    "#WRITE event_type information to dataset\n",
    "con = None\n",
    "con = psycopg2.connect(database = 'event_db', user = 'elahe')\n",
    "event_type_df.to_sql('event_type_table', engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 2000\n",
      "year 2001\n",
      "year 2002\n",
      "year 2003\n",
      "year 2004\n",
      "year 2005\n",
      "year 2006\n",
      "year 2007\n",
      "year 2008\n",
      "year 2009\n",
      "year 2010\n",
      "year 2011\n",
      "year 2012\n",
      "year 2013\n",
      "year 2014\n",
      "year 2015\n",
      "year 2016\n",
      "year 2017\n",
      "   EVENT_ID MONTH_NAME  CZ_FIPS     CZ_NAME  BEGIN_LOCATION  STATE_FIPS  \\\n",
      "0   5130281   February       45       ELLIS         CATESBY        40.0   \n",
      "1   5129129    January      175  WASHINGTON  FREDDRICKSBURG        18.0   \n",
      "2   5129550   February      281    LAMPASAS        LAMPASAS        48.0   \n",
      "3   5129553   February       27        BELL         KILLEEN        48.0   \n",
      "4   5132160   February      277        TIFT           OMEGA        13.0   \n",
      "\n",
      "      STATE  YEAR  \n",
      "0  OKLAHOMA  2000  \n",
      "1   INDIANA  2000  \n",
      "2     TEXAS  2000  \n",
      "3     TEXAS  2000  \n",
      "4   GEORGIA  2000  \n",
      "   EVENT_ID MONTH_NAME  CZ_FIPS             CZ_NAME BEGIN_LOCATION  \\\n",
      "0   5165377   December       67   INLAND PALM BEACH           None   \n",
      "1   5165378   December       70      INLAND COLLIER           None   \n",
      "2   5165379   December       73         INLAND DADE           None   \n",
      "3   5165449   December       23             PRESTON           None   \n",
      "4   5128383    January       30  COASTAL WASHINGTON           None   \n",
      "\n",
      "   STATE_FIPS          STATE  YEAR  \n",
      "0        12.0        FLORIDA  2000  \n",
      "1        12.0        FLORIDA  2000  \n",
      "2        12.0        FLORIDA  2000  \n",
      "3        54.0  WEST VIRGINIA  2000  \n",
      "4        23.0          MAINE  2000  \n",
      "   EVENT_ID MONTH_NAME  CZ_FIPS                                  CZ_NAME  \\\n",
      "0   5129281    January       22                       CURRY COUNTY COAST   \n",
      "1   5128587   February      163                                 SULLIVAN   \n",
      "2   5129282    January       24  EASTERN CURRY COUNTY & JOSEPHINE COUNTY   \n",
      "3   5128936   February        8                                  JACKSON   \n",
      "4   5128937   February        5                                    WAYNE   \n",
      "\n",
      "  BEGIN_LOCATION  STATE_FIPS          STATE  YEAR  \n",
      "0           None        41.0         OREGON  2000  \n",
      "1     BLUFF CITY        47.0      TENNESSEE  2000  \n",
      "2           None        41.0         OREGON  2000  \n",
      "3           None        54.0  WEST VIRGINIA  2000  \n",
      "4           None        54.0  WEST VIRGINIA  2000  \n"
     ]
    }
   ],
   "source": [
    " \n",
    "#Read event information from all the tables\n",
    "location_list = []\n",
    "#location_ids=[]\n",
    "cnt=0\n",
    "# get the table names after the year 2000 the reason is before that all the events are mostly tornado\n",
    "#later on if we decide to use all the tables it is better to normalize number of events base on the \n",
    "#previous years for the model not to be biased towards tornado\n",
    "\n",
    "#use a regexp to get the numbers out of string\n",
    "\n",
    "event_location_tornado_list = []\n",
    "event_location_cold_list = []\n",
    "event_location_wet_list = []\n",
    "event_location_no_event_list=[]\n",
    "\n",
    "for table_name in table_names:\n",
    "\n",
    "    year = int(re.findall(r'\\d+', table_name)[0])\n",
    "    if year >=2000:\n",
    "        print 'year %s'%(str(year))\n",
    "        # query: \n",
    "        #for sql query you don't need to put column names into \"\" but if the column names are \n",
    "        #in UPPER CASE LETTERS you have to do that\n",
    "       \n",
    "        cond = r'%Tornado%'\n",
    "        sql_query_tornado = \"\"\"\n",
    "        select \"EVENT_ID\",\"MONTH_NAME\",\"CZ_FIPS\",\"CZ_NAME\",\"BEGIN_LOCATION\",\"STATE_FIPS\",\"STATE\" FROM %s WHERE \"EVENT_TYPE\" like '%s';\n",
    "        \"\"\" %(table_name,cond)\n",
    "        #print sql_query_tornado\n",
    "        event_location_from_sql = pd.read_sql_query(sql_query_tornado,con)\n",
    "        event_location_from_sql['YEAR']=year\n",
    "        event_location_tornado_list.append(event_location_from_sql)\n",
    "        \n",
    "        cond1 = r'%Chill%'\n",
    "        cond2 = r'%Winter%'\n",
    "        cond3 = r'%Blizzard%'\n",
    "        cond4 = r'%Snow%'\n",
    "        cond5 = r'%Ice' \n",
    "        sql_query_cold = \"\"\"\n",
    "        select \"EVENT_ID\",\"MONTH_NAME\",\"CZ_FIPS\",\"CZ_NAME\",\"BEGIN_LOCATION\",\"STATE_FIPS\",\"STATE\" FROM %s \n",
    "        WHERE \"EVENT_TYPE\" like '%s'\n",
    "        or \"EVENT_TYPE\" like '%s'\n",
    "        or \"EVENT_TYPE\" like '%s'\n",
    "        or \"EVENT_TYPE\" like '%s'\n",
    "        or \"EVENT_TYPE\" like '%s';\n",
    "        \"\"\" %(table_name,cond1,cond2,cond3,cond4,cond5)\n",
    "        event_location_from_sql = pd.read_sql_query(sql_query_cold,con)\n",
    "        event_location_from_sql['YEAR']=year\n",
    "        event_location_cold_list.append(event_location_from_sql)\n",
    "        \n",
    "        cond1 = r'Flood'\n",
    "        cond2 = r'%Rain%'\n",
    "        cond3 = r'%Lightning%'\n",
    "        sql_query_wet = \"\"\"\n",
    "        select \"EVENT_ID\",\"MONTH_NAME\",\"CZ_FIPS\",\"CZ_NAME\",\"BEGIN_LOCATION\",\"STATE_FIPS\",\"STATE\" FROM %s \n",
    "        WHERE \"EVENT_TYPE\" like '%s'\n",
    "        or \"EVENT_TYPE\" like '%s'\n",
    "        or \"EVENT_TYPE\" like '%s';\n",
    "        \"\"\" %(table_name,cond1,cond2,cond3)\n",
    "        #print sql_query\n",
    "        event_location_from_sql = pd.read_sql_query(sql_query_wet,con)\n",
    "        event_location_from_sql['YEAR']=year\n",
    "        event_location_wet_list.append(event_location_from_sql)\n",
    "        \n",
    "############## to ither weather conditions to add later         \n",
    "##cond1 = r'%Heat%'\n",
    "##cond2 = r'%Waterspout%'\n",
    "\n",
    "#-----\n",
    "#cond1 = r'%Hurricane%'\n",
    "\n",
    "event_location_tornado_df =pd.concat(event_location_tornado_list,axis=0)\n",
    "event_location_cold_df =pd.concat(event_location_cold_list,axis=0)\n",
    "event_location_wet_df =pd.concat(event_location_wet_list,axis=0)\n",
    "\n",
    "print event_location_tornado_df.head()\n",
    "print event_location_cold_df.head()\n",
    "print event_location_wet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write Tornado\n",
      "write Cold\n",
      "write wet\n"
     ]
    }
   ],
   "source": [
    "#connect to dataset:\n",
    "#WRITE event_type information to dataset\n",
    "print 'write Tornado'\n",
    "event_location_tornado_df.to_sql('event_location_tornado_table', engine, if_exists='replace',index=False)\n",
    "print 'write Cold'\n",
    "event_location_cold_df.to_sql('event_location_cold_table', engine, if_exists='replace',index=False)\n",
    "print 'write wet'\n",
    "event_location_wet_df.to_sql('event_location_wet_table', engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python get_rita.py --year 2014 --month 1 --data_path data/\n",
      "python get_rita.py --year 2014 --month 2 --data_path data/\n",
      "python get_rita.py --year 2014 --month 3 --data_path data/\n",
      "python get_rita.py --year 2014 --month 4 --data_path data/\n",
      "python get_rita.py --year 2014 --month 5 --data_path data/\n",
      "python get_rita.py --year 2014 --month 6 --data_path data/\n",
      "python get_rita.py --year 2014 --month 7 --data_path data/\n",
      "python get_rita.py --year 2014 --month 8 --data_path data/\n",
      "python get_rita.py --year 2014 --month 9 --data_path data/\n",
      "python get_rita.py --year 2014 --month 10 --data_path data/\n",
      "python get_rita.py --year 2014 --month 11 --data_path data/\n",
      "python get_rita.py --year 2014 --month 12 --data_path data/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filepath='/Users/elahe/Desktop/Insight/EscapeDisaster/getRita/' \n",
    "os.chdir(filepath)\n",
    "#the current year data is always till the last 3 months we don't include the data all togeter\n",
    "year_range = range(2014,2015)\n",
    "month_range = range(1,13)\n",
    "for year in year_range:\n",
    "    for month in month_range:\n",
    "        cmd = \"python get_rita.py --year %d --month %d --data_path %s\" %(year,month,\"data/\")\n",
    "        print cmd\n",
    "        os.system(cmd)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After manually extacting the files and changing the name to \"2015_1\", \"2015_2\",.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proccessing 2013_1.csv\n",
      "(509519, 22)\n",
      "proccessing 2013_2.csv\n",
      "(469746, 22)\n",
      "proccessing 2013_3.csv\n",
      "(552312, 22)\n",
      "proccessing 2013_4.csv\n",
      "(536393, 22)\n",
      "proccessing 2013_5.csv\n",
      "(548642, 22)\n",
      "proccessing 2013_6.csv\n",
      "(552141, 22)\n",
      "proccessing 2013_7.csv\n",
      "(571623, 22)"
     ]
    }
   ],
   "source": [
    "%%notify\n",
    "import os\n",
    "filepath='/Users/elahe/Desktop/Insight/EscapeDisaster/getRita/data/' \n",
    "os.chdir(filepath)\n",
    "year_range = range(2013,2017)\n",
    "month_range = range(1,13)\n",
    "flight_month_list = []\n",
    "num_flights_list = []\n",
    "for year in year_range:\n",
    "    for month in month_range:\n",
    "        filename=\"%d_%d.csv\" %(year,month)\n",
    "        print 'proccessing %s' %filename\n",
    "        flight_month = pd.DataFrame.from_csv(filename)\n",
    "       \n",
    "        flight_month = flight_month.rename(columns=lambda x: x.strip())\n",
    "\n",
    "        print flight_month.shape\n",
    "        flight_month['counts_total_dest'] = flight_month.groupby([\"FL_DATE\",'DEST_CITY_NAME'])['DEST_CITY_NAME'].transform('count')\n",
    "        flight_month['counts_total_origin'] = flight_month.groupby([\"FL_DATE\",'ORIGIN_CITY_NAME'])['ORIGIN_CITY_NAME'].transform('count')\n",
    "        #flight_month['counts_origin'] = flight_month.groupby([\"FL_DATE\",'ORIGIN_CITY_NAME'])['ORIGIN_CITY_NAME'].transform('count')\n",
    "        flight_month_old = flight_month\n",
    "        num_flights = flight_month[['counts_total_dest','FL_DATE','DEST_CITY_NAME']].drop_duplicates()\n",
    "        flight_month = flight_month[['DAY_OF_MONTH','MONTH','FL_DATE','ORIGIN_CITY_NAME','ORIGIN_STATE_FIPS','DEST_CITY_NAME','DEST_STATE_FIPS','CANCELLED',\"CANCELLATION_CODE\",'WEATHER_DELAY']]\n",
    "        #print flight_month.shape\n",
    "        ### This count is just to know if the cancelation was due to bad weather conditions in destination\n",
    "        ### or origin\n",
    "    \n",
    "        \n",
    "        flight_month = flight_month[((flight_month['CANCELLED'] == 1) & (flight_month[\"CANCELLATION_CODE\"] == 'B')) | (flight_month['WEATHER_DELAY']==1)]\n",
    "        flight_month = flight_month.fillna(0)\n",
    "        flight_month.drop('CANCELLATION_CODE',axis=1)\n",
    "       \n",
    "        flight_month['counts_origin'] = flight_month.groupby([\"FL_DATE\",'ORIGIN_CITY_NAME'])['ORIGIN_CITY_NAME'].transform('count')\n",
    "        flight_month.loc[:,'counts_origin'] *= 1.0 \n",
    "        flight_month['counts_dest'] = flight_month.groupby([\"FL_DATE\",'DEST_CITY_NAME'])['DEST_CITY_NAME'].transform('count')\n",
    "            \n",
    "        origin_total_df=flight_month_old[['counts_total_origin','ORIGIN_CITY_NAME','FL_DATE']].drop_duplicates()\n",
    "        dest_total_df=flight_month_old[['counts_total_dest','DEST_CITY_NAME','FL_DATE']].drop_duplicates()\n",
    "        flight_month = pd.merge(flight_month,origin_total_df,how='left',on=['ORIGIN_CITY_NAME','FL_DATE'])\n",
    "        flight_month = pd.merge(flight_month,dest_total_df,how='left',on=['DEST_CITY_NAME','FL_DATE'])\n",
    "        \n",
    "        \n",
    "        #print flight_month['counts_origin']/flight_month['counts_total_origin']\n",
    "        #df[['B','C']].div(df.A, axis=0)\n",
    "        flight_month['normalized_cancel_origin']=flight_month['counts_origin'].div(flight_month.counts_total_origin)\n",
    "        flight_month['normalized_cancel_dest']=flight_month['counts_dest'].div(flight_month.counts_total_dest)\n",
    "        #flight_month['normalized_cancel_origin']=np.where(flight_month['counts_total_origin'], flight_month['counts_origin'], flight_month['counts_origin']/flight_month['counts_total_origin'])\n",
    "        flight_month = flight_month[['DAY_OF_MONTH','MONTH','FL_DATE','ORIGIN_CITY_NAME','ORIGIN_STATE_FIPS','DEST_CITY_NAME','DEST_STATE_FIPS','CANCELLED',\"CANCELLATION_CODE\",'WEATHER_DELAY','normalized_cancel_origin','normalized_cancel_dest']]\n",
    "        flight_month = flight_month[(flight_month['normalized_cancel_dest']*10.0>flight_month['normalized_cancel_origin'])]\n",
    "        flight_month = flight_month[['DAY_OF_MONTH','MONTH','FL_DATE','DEST_CITY_NAME','DEST_STATE_FIPS','normalized_cancel_dest']]\n",
    "        flight_month_list.append(flight_month)\n",
    "        \n",
    "    print \"---------concating dataframes for months----\"\n",
    "    flight_year =pd.concat(flight_month_list,axis=0)\n",
    "\n",
    "    print \"---------Writing to dataset----\"\n",
    "    flight_year.to_sql(('flight%d_table' %year), engine, if_exists='replace',index=False)\n",
    "    \n",
    "##### LATER ON USER num_flights per day to destination for normalization of number of flights canceled    \n",
    "print flight_year.head()\n",
    "print flight_year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   zip_code   latitude  longitude        city state     county\n",
      "0       501  40.922326 -72.637078  Holtsville    NY    Suffolk\n",
      "1       544  40.922326 -72.637078  Holtsville    NY    Suffolk\n",
      "2       601  18.165273 -66.722583    Adjuntas    PR   Adjuntas\n",
      "3       602  18.393103 -67.180953      Aguada    PR     Aguada\n",
      "4       603  18.455913 -67.145780   Aguadilla    PR  Aguadilla\n"
     ]
    }
   ],
   "source": [
    "# read a database from CSV and load it into a pandas dataframe\n",
    "stateZip = pd.DataFrame.from_csv('Data/stateZip.csv',index_col= None)\n",
    "zipcode = pd.DataFrame.from_csv('Data/ZIPCODE.csv',index_col= None)\n",
    "states = pd.DataFrame.from_csv('Data/STATES.csv',index_col= None)\n",
    "print zipcode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('Data/national_county.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\",\") for line in stripped if line)\n",
    "    with open('Data/countyFIPS.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('STATE_AB','STATE_FIPS','COUNTY_FIPS','COUNTY_NAME','ACTIVE'))\n",
    "        writer.writerows(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1930,)\n",
      "(18953,)\n",
      "(58,)\n",
      "(63,)\n",
      "(58,)\n",
      "(57,)\n",
      "(57,)\n",
      "(62,)\n",
      "(69,)\n"
     ]
    }
   ],
   "source": [
    "print stateZip.county.unique().shape\n",
    "print stateZip.city.unique().shape\n",
    "\n",
    "print stateZip.STATE_NAME.unique().shape\n",
    "print stateZip.STATE_AB.unique().shape\n",
    "print stateZip.STATE_FIPS.unique().shape\n",
    "\n",
    "print states.STATE_FIPS.unique().shape\n",
    "print states.STATE_NAME.unique().shape\n",
    "\n",
    "print zipcode.state.unique().shape\n",
    "\n",
    "print location_df.STATE.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stateZip = stateZip.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>STATE_AB</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.922326</td>\n",
       "      <td>-72.637078</td>\n",
       "      <td>501.0</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>36103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.922326</td>\n",
       "      <td>-72.637078</td>\n",
       "      <td>544.0</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Holtsville</td>\n",
       "      <td>NY</td>\n",
       "      <td>36103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.992288</td>\n",
       "      <td>-72.723496</td>\n",
       "      <td>6390.0</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Fishers Island</td>\n",
       "      <td>NY</td>\n",
       "      <td>36103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.750422</td>\n",
       "      <td>-73.996328</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.718758</td>\n",
       "      <td>-73.986427</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.730223</td>\n",
       "      <td>-73.988564</td>\n",
       "      <td>10003.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.696355</td>\n",
       "      <td>-74.025276</td>\n",
       "      <td>10004.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.706903</td>\n",
       "      <td>-74.008654</td>\n",
       "      <td>10005.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.708834</td>\n",
       "      <td>-74.013168</td>\n",
       "      <td>10006.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.713941</td>\n",
       "      <td>-74.007401</td>\n",
       "      <td>10007.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.780751</td>\n",
       "      <td>-73.977182</td>\n",
       "      <td>10008.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.727750</td>\n",
       "      <td>-73.980396</td>\n",
       "      <td>10009.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.739024</td>\n",
       "      <td>-73.983542</td>\n",
       "      <td>10010.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.740916</td>\n",
       "      <td>-73.999769</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.729124</td>\n",
       "      <td>-73.991582</td>\n",
       "      <td>10012.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.722105</td>\n",
       "      <td>-74.003497</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.738088</td>\n",
       "      <td>-74.005095</td>\n",
       "      <td>10014.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.780751</td>\n",
       "      <td>-73.977182</td>\n",
       "      <td>10015.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.745527</td>\n",
       "      <td>-73.978449</td>\n",
       "      <td>10016.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.752955</td>\n",
       "      <td>-73.973196</td>\n",
       "      <td>10017.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.755332</td>\n",
       "      <td>-73.993172</td>\n",
       "      <td>10018.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.765926</td>\n",
       "      <td>-73.985443</td>\n",
       "      <td>10019.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.735449</td>\n",
       "      <td>-73.996788</td>\n",
       "      <td>10020.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.768823</td>\n",
       "      <td>-73.960257</td>\n",
       "      <td>10021.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.758775</td>\n",
       "      <td>-73.967842</td>\n",
       "      <td>10022.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.776765</td>\n",
       "      <td>-73.982213</td>\n",
       "      <td>10023.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.808130</td>\n",
       "      <td>-73.965653</td>\n",
       "      <td>10024.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.798664</td>\n",
       "      <td>-73.967778</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.802918</td>\n",
       "      <td>-73.953107</td>\n",
       "      <td>10026.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.812242</td>\n",
       "      <td>-73.953200</td>\n",
       "      <td>10027.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>36061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42012</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.197581</td>\n",
       "      <td>-122.162076</td>\n",
       "      <td>98372.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Puyallup</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42013</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.145817</td>\n",
       "      <td>-122.309704</td>\n",
       "      <td>98373.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Puyallup</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42014</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.139095</td>\n",
       "      <td>-122.258646</td>\n",
       "      <td>98374.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Puyallup</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42015</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.098845</td>\n",
       "      <td>-122.363930</td>\n",
       "      <td>98375.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Puyallup</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42016</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.828495</td>\n",
       "      <td>-122.838769</td>\n",
       "      <td>98376.0</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Quilcene</td>\n",
       "      <td>WA</td>\n",
       "      <td>53031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42017</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>46.516754</td>\n",
       "      <td>-121.894411</td>\n",
       "      <td>98377.0</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Randle</td>\n",
       "      <td>WA</td>\n",
       "      <td>53041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42018</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.687971</td>\n",
       "      <td>-122.729304</td>\n",
       "      <td>98378.0</td>\n",
       "      <td>Kitsap</td>\n",
       "      <td>Retsil</td>\n",
       "      <td>WA</td>\n",
       "      <td>53035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42019</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.591261</td>\n",
       "      <td>-122.868581</td>\n",
       "      <td>98380.0</td>\n",
       "      <td>Kitsap</td>\n",
       "      <td>Seabeck</td>\n",
       "      <td>WA</td>\n",
       "      <td>53035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42020</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>48.288633</td>\n",
       "      <td>-124.397803</td>\n",
       "      <td>98381.0</td>\n",
       "      <td>Clallam</td>\n",
       "      <td>Sekiu</td>\n",
       "      <td>WA</td>\n",
       "      <td>53009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42021</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>48.067730</td>\n",
       "      <td>-123.080362</td>\n",
       "      <td>98382.0</td>\n",
       "      <td>Clallam</td>\n",
       "      <td>Sequim</td>\n",
       "      <td>WA</td>\n",
       "      <td>53009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42022</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.672498</td>\n",
       "      <td>-122.707982</td>\n",
       "      <td>98383.0</td>\n",
       "      <td>Kitsap</td>\n",
       "      <td>Silverdale</td>\n",
       "      <td>WA</td>\n",
       "      <td>53035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42023</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.521803</td>\n",
       "      <td>-122.539637</td>\n",
       "      <td>98384.0</td>\n",
       "      <td>Kitsap</td>\n",
       "      <td>South Colby</td>\n",
       "      <td>WA</td>\n",
       "      <td>53035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42024</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.138271</td>\n",
       "      <td>-122.096799</td>\n",
       "      <td>98385.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>South Prairie</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42025</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.510370</td>\n",
       "      <td>-122.499139</td>\n",
       "      <td>98386.0</td>\n",
       "      <td>Kitsap</td>\n",
       "      <td>Southworth</td>\n",
       "      <td>WA</td>\n",
       "      <td>53035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42026</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.058452</td>\n",
       "      <td>-122.416480</td>\n",
       "      <td>98387.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Spanaway</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42027</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.132671</td>\n",
       "      <td>-122.331781</td>\n",
       "      <td>98388.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Steilacoom</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42028</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.176966</td>\n",
       "      <td>-122.159820</td>\n",
       "      <td>98390.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Sumner</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42029</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.732624</td>\n",
       "      <td>-122.564557</td>\n",
       "      <td>98392.0</td>\n",
       "      <td>Kitsap</td>\n",
       "      <td>Suquamish</td>\n",
       "      <td>WA</td>\n",
       "      <td>53035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42030</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.626717</td>\n",
       "      <td>-122.649953</td>\n",
       "      <td>98393.0</td>\n",
       "      <td>Kitsap</td>\n",
       "      <td>Tracyton</td>\n",
       "      <td>WA</td>\n",
       "      <td>53035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42031</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.311117</td>\n",
       "      <td>-122.772503</td>\n",
       "      <td>98394.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Vaughn</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42032</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.266017</td>\n",
       "      <td>-122.832799</td>\n",
       "      <td>98395.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Wauna</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42033</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.109524</td>\n",
       "      <td>-122.037015</td>\n",
       "      <td>98396.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Wilkeson</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42034</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.066193</td>\n",
       "      <td>-122.113223</td>\n",
       "      <td>98397.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Longmire</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42035</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.066193</td>\n",
       "      <td>-122.113223</td>\n",
       "      <td>98398.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Paradise Inn</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42036</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.253671</td>\n",
       "      <td>-122.444335</td>\n",
       "      <td>98401.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42037</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.261502</td>\n",
       "      <td>-122.463308</td>\n",
       "      <td>98402.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42038</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.265371</td>\n",
       "      <td>-122.457087</td>\n",
       "      <td>98403.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42039</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.209131</td>\n",
       "      <td>-122.397929</td>\n",
       "      <td>98404.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42040</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.247871</td>\n",
       "      <td>-122.472793</td>\n",
       "      <td>98405.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42041</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>47.259216</td>\n",
       "      <td>-122.509235</td>\n",
       "      <td>98406.0</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>53053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42042 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATE_FIPS  STATE_NAME   latitude   longitude  zip_code     county  \\\n",
       "0            36.0    New York  40.922326  -72.637078     501.0    Suffolk   \n",
       "1            36.0    New York  40.922326  -72.637078     544.0    Suffolk   \n",
       "2            36.0    New York  40.992288  -72.723496    6390.0    Suffolk   \n",
       "3            36.0    New York  40.750422  -73.996328   10001.0   New York   \n",
       "4            36.0    New York  40.718758  -73.986427   10002.0   New York   \n",
       "5            36.0    New York  40.730223  -73.988564   10003.0   New York   \n",
       "6            36.0    New York  40.696355  -74.025276   10004.0   New York   \n",
       "7            36.0    New York  40.706903  -74.008654   10005.0   New York   \n",
       "8            36.0    New York  40.708834  -74.013168   10006.0   New York   \n",
       "9            36.0    New York  40.713941  -74.007401   10007.0   New York   \n",
       "10           36.0    New York  40.780751  -73.977182   10008.0   New York   \n",
       "11           36.0    New York  40.727750  -73.980396   10009.0   New York   \n",
       "12           36.0    New York  40.739024  -73.983542   10010.0   New York   \n",
       "13           36.0    New York  40.740916  -73.999769   10011.0   New York   \n",
       "14           36.0    New York  40.729124  -73.991582   10012.0   New York   \n",
       "15           36.0    New York  40.722105  -74.003497   10013.0   New York   \n",
       "16           36.0    New York  40.738088  -74.005095   10014.0   New York   \n",
       "17           36.0    New York  40.780751  -73.977182   10015.0   New York   \n",
       "18           36.0    New York  40.745527  -73.978449   10016.0   New York   \n",
       "19           36.0    New York  40.752955  -73.973196   10017.0   New York   \n",
       "20           36.0    New York  40.755332  -73.993172   10018.0   New York   \n",
       "21           36.0    New York  40.765926  -73.985443   10019.0   New York   \n",
       "22           36.0    New York  40.735449  -73.996788   10020.0   New York   \n",
       "23           36.0    New York  40.768823  -73.960257   10021.0   New York   \n",
       "24           36.0    New York  40.758775  -73.967842   10022.0   New York   \n",
       "25           36.0    New York  40.776765  -73.982213   10023.0   New York   \n",
       "26           36.0    New York  40.808130  -73.965653   10024.0   New York   \n",
       "27           36.0    New York  40.798664  -73.967778   10025.0   New York   \n",
       "28           36.0    New York  40.802918  -73.953107   10026.0   New York   \n",
       "29           36.0    New York  40.812242  -73.953200   10027.0   New York   \n",
       "...           ...         ...        ...         ...       ...        ...   \n",
       "42012        53.0  Washington  47.197581 -122.162076   98372.0     Pierce   \n",
       "42013        53.0  Washington  47.145817 -122.309704   98373.0     Pierce   \n",
       "42014        53.0  Washington  47.139095 -122.258646   98374.0     Pierce   \n",
       "42015        53.0  Washington  47.098845 -122.363930   98375.0     Pierce   \n",
       "42016        53.0  Washington  47.828495 -122.838769   98376.0  Jefferson   \n",
       "42017        53.0  Washington  46.516754 -121.894411   98377.0      Lewis   \n",
       "42018        53.0  Washington  47.687971 -122.729304   98378.0     Kitsap   \n",
       "42019        53.0  Washington  47.591261 -122.868581   98380.0     Kitsap   \n",
       "42020        53.0  Washington  48.288633 -124.397803   98381.0    Clallam   \n",
       "42021        53.0  Washington  48.067730 -123.080362   98382.0    Clallam   \n",
       "42022        53.0  Washington  47.672498 -122.707982   98383.0     Kitsap   \n",
       "42023        53.0  Washington  47.521803 -122.539637   98384.0     Kitsap   \n",
       "42024        53.0  Washington  47.138271 -122.096799   98385.0     Pierce   \n",
       "42025        53.0  Washington  47.510370 -122.499139   98386.0     Kitsap   \n",
       "42026        53.0  Washington  47.058452 -122.416480   98387.0     Pierce   \n",
       "42027        53.0  Washington  47.132671 -122.331781   98388.0     Pierce   \n",
       "42028        53.0  Washington  47.176966 -122.159820   98390.0     Pierce   \n",
       "42029        53.0  Washington  47.732624 -122.564557   98392.0     Kitsap   \n",
       "42030        53.0  Washington  47.626717 -122.649953   98393.0     Kitsap   \n",
       "42031        53.0  Washington  47.311117 -122.772503   98394.0     Pierce   \n",
       "42032        53.0  Washington  47.266017 -122.832799   98395.0     Pierce   \n",
       "42033        53.0  Washington  47.109524 -122.037015   98396.0     Pierce   \n",
       "42034        53.0  Washington  47.066193 -122.113223   98397.0     Pierce   \n",
       "42035        53.0  Washington  47.066193 -122.113223   98398.0     Pierce   \n",
       "42036        53.0  Washington  47.253671 -122.444335   98401.0     Pierce   \n",
       "42037        53.0  Washington  47.261502 -122.463308   98402.0     Pierce   \n",
       "42038        53.0  Washington  47.265371 -122.457087   98403.0     Pierce   \n",
       "42039        53.0  Washington  47.209131 -122.397929   98404.0     Pierce   \n",
       "42040        53.0  Washington  47.247871 -122.472793   98405.0     Pierce   \n",
       "42041        53.0  Washington  47.259216 -122.509235   98406.0     Pierce   \n",
       "\n",
       "                 city STATE_AB   fips  \n",
       "0          Holtsville       NY  36103  \n",
       "1          Holtsville       NY  36103  \n",
       "2      Fishers Island       NY  36103  \n",
       "3            New York       NY  36061  \n",
       "4            New York       NY  36061  \n",
       "5            New York       NY  36061  \n",
       "6            New York       NY  36061  \n",
       "7            New York       NY  36061  \n",
       "8            New York       NY  36061  \n",
       "9            New York       NY  36061  \n",
       "10           New York       NY  36061  \n",
       "11           New York       NY  36061  \n",
       "12           New York       NY  36061  \n",
       "13           New York       NY  36061  \n",
       "14           New York       NY  36061  \n",
       "15           New York       NY  36061  \n",
       "16           New York       NY  36061  \n",
       "17           New York       NY  36061  \n",
       "18           New York       NY  36061  \n",
       "19           New York       NY  36061  \n",
       "20           New York       NY  36061  \n",
       "21           New York       NY  36061  \n",
       "22           New York       NY  36061  \n",
       "23           New York       NY  36061  \n",
       "24           New York       NY  36061  \n",
       "25           New York       NY  36061  \n",
       "26           New York       NY  36061  \n",
       "27           New York       NY  36061  \n",
       "28           New York       NY  36061  \n",
       "29           New York       NY  36061  \n",
       "...               ...      ...    ...  \n",
       "42012        Puyallup       WA  53053  \n",
       "42013        Puyallup       WA  53053  \n",
       "42014        Puyallup       WA  53053  \n",
       "42015        Puyallup       WA  53053  \n",
       "42016        Quilcene       WA  53031  \n",
       "42017          Randle       WA  53041  \n",
       "42018          Retsil       WA  53035  \n",
       "42019         Seabeck       WA  53035  \n",
       "42020           Sekiu       WA  53009  \n",
       "42021          Sequim       WA  53009  \n",
       "42022      Silverdale       WA  53035  \n",
       "42023     South Colby       WA  53035  \n",
       "42024   South Prairie       WA  53053  \n",
       "42025      Southworth       WA  53035  \n",
       "42026        Spanaway       WA  53053  \n",
       "42027      Steilacoom       WA  53053  \n",
       "42028          Sumner       WA  53053  \n",
       "42029       Suquamish       WA  53035  \n",
       "42030        Tracyton       WA  53035  \n",
       "42031          Vaughn       WA  53053  \n",
       "42032           Wauna       WA  53053  \n",
       "42033        Wilkeson       WA  53053  \n",
       "42034        Longmire       WA  53053  \n",
       "42035    Paradise Inn       WA  53053  \n",
       "42036          Tacoma       WA  53053  \n",
       "42037          Tacoma       WA  53053  \n",
       "42038          Tacoma       WA  53053  \n",
       "42039          Tacoma       WA  53053  \n",
       "42040          Tacoma       WA  53053  \n",
       "42041          Tacoma       WA  53053  \n",
       "\n",
       "[42042 rows x 9 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import addfips\n",
    "af = addfips.AddFIPS()\n",
    "new_rows=[]\n",
    "for index, row in stateZip.iterrows():\n",
    "    af.add_county_fips(row, county_field=\"county\", state_field=\"STATE_AB\")\n",
    "    stateZip.loc[index,'fips']=row['fips']\n",
    "stateZip.drop('ifor',axis=1)    \n",
    "#row = {'county': 'Cook County', 'state': 'IL'}\n",
    "#af.add_county_fips(row, county_field=\"county\", state_field=\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File Data/ZIPCODE.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-d393a9c88829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzipcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/ZIPCODE.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstateZip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/stateZip.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(cls, path, header, sep, index_col, parse_dates, encoding, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m   1259\u001b[0m                           \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                           \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtupleize_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m                           infer_datetime_format=infer_datetime_format)\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File Data/ZIPCODE.csv does not exist"
     ]
    }
   ],
   "source": [
    "stateZip.to_csv('Data/stateZip.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stateZip = pd.DataFrame.from_csv('/Users/elahe/Desktop/Insight/EscapeDisaster/Data/stateZip.csv',index_col= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = None\n",
    "con = psycopg2.connect(database = 'event_db', user = 'elahe')\n",
    "stateZip.to_sql('state_zip_table', engine, if_exists='replace',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STATE_FIPS STATE_NAME   latitude  longitude  zip_code    county  \\\n",
      "0        36.0   New York  40.922326 -72.637078     501.0   Suffolk   \n",
      "1        36.0   New York  40.922326 -72.637078     544.0   Suffolk   \n",
      "2        36.0   New York  40.992288 -72.723496    6390.0   Suffolk   \n",
      "3        36.0   New York  40.750422 -73.996328   10001.0  New York   \n",
      "4        36.0   New York  40.718758 -73.986427   10002.0  New York   \n",
      "\n",
      "             city STATE_AB  ifor     fips  \n",
      "0      Holtsville       NY   NaN  36103.0  \n",
      "1      Holtsville       NY   NaN  36103.0  \n",
      "2  Fishers Island       NY   NaN  36103.0  \n",
      "3        New York       NY   NaN  36061.0  \n",
      "4        New York       NY   NaN  36061.0  \n"
     ]
    }
   ],
   "source": [
    "print stateZip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   county_avg_lat  county_avg_lon  STATE_FIPS     fips\n",
      "0       36.750321      -83.705986        21.0  21013.0\n",
      "1       40.407972      -91.675600        29.0  29045.0\n",
      "2       32.781917      -87.929252         1.0   1063.0\n",
      "3       40.146342      -96.213025        31.0  31133.0\n",
      "4       34.295375      -91.928854         5.0   5069.0\n",
      "(3159, 4)\n",
      "   county_avg_lat  county_avg_lon  STATE_FIPS     fips CZ_FIPS\n",
      "0       36.750321      -83.705986        21.0  21013.0      13\n",
      "1       40.407972      -91.675600        29.0  29045.0      45\n",
      "2       32.781917      -87.929252         1.0   1063.0      63\n",
      "3       40.146342      -96.213025        31.0  31133.0     133\n",
      "4       34.295375      -91.928854         5.0   5069.0      69\n",
      "(3147, 5)\n"
     ]
    }
   ],
   "source": [
    "sql_query=\"\"\"\n",
    "select AVG(latitude) as county_avg_lat, AVG(longitude) \n",
    "as county_avg_lon,\"STATE_FIPS\",fips\n",
    "from state_zip_table \n",
    "group by \"STATE_FIPS\",fips;\n",
    "\"\"\"\n",
    "county_fips_lat_lon = pd.read_sql_query(sql_query,con)\n",
    "print county_fips_lat_lon.head()\n",
    "print county_fips_lat_lon.shape\n",
    "county_fips_lat_lon = county_fips_lat_lon.dropna()\n",
    "fips_series = county_fips_lat_lon['fips'].astype(int)\n",
    "fips_series = fips_series.astype(str)\n",
    "### get last 3 character of string\n",
    "fips_series = fips_series.str[-3:].astype(int).astype(str)\n",
    "county_fips_lat_lon['CZ_FIPS'] = fips_series\n",
    "print county_fips_lat_lon.head()\n",
    "print county_fips_lat_lon.shape\n",
    "county_fips_lat_lon.to_sql('county_fips_lat_lon_table', engine, if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     STATE_FIPS STATE_AB            city     fips\n",
      "0          36.0       NY      Holtsville  36103.0\n",
      "2          36.0       NY  Fishers Island  36103.0\n",
      "3          36.0       NY        New York  36061.0\n",
      "165        36.0       NY   Staten Island  36085.0\n",
      "179        36.0       NY           Bronx  36005.0\n",
      "(29641, 4)\n"
     ]
    }
   ],
   "source": [
    "sql_query=\"\"\"\n",
    "select \"STATE_FIPS\",\"STATE_AB\",city,fips\n",
    "from state_zip_table\n",
    "\"\"\"\n",
    "city_fips=pd.read_sql_query(sql_query,con)\n",
    "city_fips=city_fips.drop_duplicates()\n",
    "print city_fips.head()\n",
    "print city_fips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stateZip = stateZip[['STATE_FIPS','STATE_AB','city','fips']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = None\n",
    "con = psycopg2.connect(database = 'event_db', user = 'elahe')\n",
    "city_fips.to_sql('city_fips_table', engine, if_exists='replace',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         STATE  CZ_FIPS  STATE_FIPS CZ_TYPE     CZ_NAME CZ_TIMEZONE  \\\n",
      "0  MISSISSIPPI       87        28.0       C     LOWNDES         CST   \n",
      "1       KANSAS       63        20.0       C        GOVE         CST   \n",
      "2        TEXAS      225        48.0       C     HOUSTON         CST   \n",
      "3     OKLAHOMA       33        40.0       C      COTTON         CST   \n",
      "4     OKLAHOMA       73        40.0       C  KINGFISHER         CST   \n",
      "\n",
      "   LOCATION_ID  \n",
      "0            0  \n",
      "1            1  \n",
      "2            2  \n",
      "3            3  \n",
      "4            4  \n"
     ]
    }
   ],
   "source": [
    "print location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######READ THIS TABLES AND SAVE THEM INCSV FOR YOUR MODEL\n",
    "\n",
    "sql_query = \"\"\"\n",
    "    select * \n",
    "    from flight_df_table;\n",
    "    \"\"\"\n",
    "flight_df = pd.read_sql_query(sql_query,con)\n",
    "flight_df.to_csv('flight_df_table.csv',index=False)\n",
    "sql_query = \"\"\"\n",
    "    select * \n",
    "    from city_fips_table;\n",
    "    \"\"\"\n",
    "city_fips= pd.read_sql_query(sql_query,con)\n",
    "city_fips.to_csv('city_fips_table.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancel_freq</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEST_CITY</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.081065</td>\n",
       "      <td>2</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.139058</td>\n",
       "      <td>12</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.685847</td>\n",
       "      <td>11</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.729064</td>\n",
       "      <td>5</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.282878</td>\n",
       "      <td>9</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.508660</td>\n",
       "      <td>3</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.630769</td>\n",
       "      <td>1</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.643592</td>\n",
       "      <td>4</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.079972</td>\n",
       "      <td>6</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.555285</td>\n",
       "      <td>8</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.224798</td>\n",
       "      <td>7</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.574916</td>\n",
       "      <td>2</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.393382</td>\n",
       "      <td>12</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>11</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.269841</td>\n",
       "      <td>5</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.083478</td>\n",
       "      <td>9</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.476190</td>\n",
       "      <td>3</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.956178</td>\n",
       "      <td>1</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>4</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.078462</td>\n",
       "      <td>6</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.394591</td>\n",
       "      <td>8</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.400385</td>\n",
       "      <td>7</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>Madison</td>\n",
       "      <td>55025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.211962</td>\n",
       "      <td>7</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.211962</td>\n",
       "      <td>7</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>39025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.211962</td>\n",
       "      <td>7</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>39015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.212240</td>\n",
       "      <td>6</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.212240</td>\n",
       "      <td>6</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>39025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.212240</td>\n",
       "      <td>6</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>39015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.186508</td>\n",
       "      <td>8</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.186508</td>\n",
       "      <td>8</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>39025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4586</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>10</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>Bozeman</td>\n",
       "      <td>30031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>0.627778</td>\n",
       "      <td>3</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>Bozeman</td>\n",
       "      <td>30031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>4</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>Bozeman</td>\n",
       "      <td>30031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>2</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>Bozeman</td>\n",
       "      <td>30031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>0.419298</td>\n",
       "      <td>12</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>Bozeman</td>\n",
       "      <td>30031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>5</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>Bozeman</td>\n",
       "      <td>30031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4592</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>Brunswick, GA</td>\n",
       "      <td>Brunswick</td>\n",
       "      <td>13127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>Brunswick, GA</td>\n",
       "      <td>Brunswick</td>\n",
       "      <td>13127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>Brunswick, GA</td>\n",
       "      <td>Brunswick</td>\n",
       "      <td>13127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>Brunswick, GA</td>\n",
       "      <td>Brunswick</td>\n",
       "      <td>13127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>Brunswick, GA</td>\n",
       "      <td>Brunswick</td>\n",
       "      <td>13127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>6.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>Brunswick, GA</td>\n",
       "      <td>Brunswick</td>\n",
       "      <td>13127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Twin Falls, ID</td>\n",
       "      <td>Twin Falls</td>\n",
       "      <td>16083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>1.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>Twin Falls, ID</td>\n",
       "      <td>Twin Falls</td>\n",
       "      <td>16083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>Twin Falls, ID</td>\n",
       "      <td>Twin Falls</td>\n",
       "      <td>16083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4601</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>Twin Falls, ID</td>\n",
       "      <td>Twin Falls</td>\n",
       "      <td>16083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>Bellingham, WA</td>\n",
       "      <td>Bellingham</td>\n",
       "      <td>53073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>Bellingham, WA</td>\n",
       "      <td>Bellingham</td>\n",
       "      <td>53073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>Columbus, GA</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>13215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>8</td>\n",
       "      <td>Columbus, GA</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>13215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>Columbus, GA</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>13215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>Columbus, GA</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>13215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>7</td>\n",
       "      <td>Columbus, GA</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>13215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>Vernal, UT</td>\n",
       "      <td>Vernal</td>\n",
       "      <td>49047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Vernal, UT</td>\n",
       "      <td>Vernal</td>\n",
       "      <td>49047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>Vernal, UT</td>\n",
       "      <td>Vernal</td>\n",
       "      <td>49047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>Lewiston, ID</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>16069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4613</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>7</td>\n",
       "      <td>Hilo, HI</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>15001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>12</td>\n",
       "      <td>Hilo, HI</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>15001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>Punta Gorda, FL</td>\n",
       "      <td>Punta Gorda</td>\n",
       "      <td>12015.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4616 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cancel_freq  MONTH   DEST_CITY_NAME    DEST_CITY     fips\n",
       "0        5.081065      2      Madison, WI      Madison  55025.0\n",
       "1        5.139058     12      Madison, WI      Madison  55025.0\n",
       "2        0.685847     11      Madison, WI      Madison  55025.0\n",
       "3        0.729064      5      Madison, WI      Madison  55025.0\n",
       "4        0.282878      9      Madison, WI      Madison  55025.0\n",
       "5        1.508660      3      Madison, WI      Madison  55025.0\n",
       "6        0.630769      1      Madison, WI      Madison  55025.0\n",
       "7        0.643592      4      Madison, WI      Madison  55025.0\n",
       "8        1.079972      6      Madison, WI      Madison  55025.0\n",
       "9        0.555285      8      Madison, WI      Madison  55025.0\n",
       "10       0.224798      7      Madison, WI      Madison  55025.0\n",
       "11       0.574916      2      Madison, WI      Madison  55025.0\n",
       "12       2.393382     12      Madison, WI      Madison  55025.0\n",
       "13       0.050000     11      Madison, WI      Madison  55025.0\n",
       "14       0.269841      5      Madison, WI      Madison  55025.0\n",
       "15       0.083478      9      Madison, WI      Madison  55025.0\n",
       "16       0.476190      3      Madison, WI      Madison  55025.0\n",
       "17       0.956178      1      Madison, WI      Madison  55025.0\n",
       "18       0.266667      4      Madison, WI      Madison  55025.0\n",
       "19       0.078462      6      Madison, WI      Madison  55025.0\n",
       "20       0.394591      8      Madison, WI      Madison  55025.0\n",
       "21       0.400385      7      Madison, WI      Madison  55025.0\n",
       "22       0.211962      7   Cincinnati, OH   Cincinnati  39061.0\n",
       "23       0.211962      7   Cincinnati, OH   Cincinnati  39025.0\n",
       "24       0.211962      7   Cincinnati, OH   Cincinnati  39015.0\n",
       "25       1.212240      6   Cincinnati, OH   Cincinnati  39061.0\n",
       "26       1.212240      6   Cincinnati, OH   Cincinnati  39025.0\n",
       "27       1.212240      6   Cincinnati, OH   Cincinnati  39015.0\n",
       "28       0.186508      8   Cincinnati, OH   Cincinnati  39061.0\n",
       "29       0.186508      8   Cincinnati, OH   Cincinnati  39025.0\n",
       "...           ...    ...              ...          ...      ...\n",
       "4586     0.125000     10      Bozeman, MT      Bozeman  30031.0\n",
       "4587     0.627778      3      Bozeman, MT      Bozeman  30031.0\n",
       "4588     0.571429      4      Bozeman, MT      Bozeman  30031.0\n",
       "4589     0.142857      2      Bozeman, MT      Bozeman  30031.0\n",
       "4590     0.419298     12      Bozeman, MT      Bozeman  30031.0\n",
       "4591     0.111111      5      Bozeman, MT      Bozeman  30031.0\n",
       "4592     0.833333      6    Brunswick, GA    Brunswick  13127.0\n",
       "4593     0.333333      1    Brunswick, GA    Brunswick  13127.0\n",
       "4594     0.333333      9    Brunswick, GA    Brunswick  13127.0\n",
       "4595     0.333333      8    Brunswick, GA    Brunswick  13127.0\n",
       "4596     0.333333      6    Brunswick, GA    Brunswick  13127.0\n",
       "4597     6.666667     10    Brunswick, GA    Brunswick  13127.0\n",
       "4598     4.000000      1   Twin Falls, ID   Twin Falls  16083.0\n",
       "4599     1.333333      2   Twin Falls, ID   Twin Falls  16083.0\n",
       "4600     1.000000     12   Twin Falls, ID   Twin Falls  16083.0\n",
       "4601     0.333333      1   Twin Falls, ID   Twin Falls  16083.0\n",
       "4602     0.333333      1   Bellingham, WA   Bellingham  53073.0\n",
       "4603     0.500000     12   Bellingham, WA   Bellingham  53073.0\n",
       "4604     0.500000      6     Columbus, GA     Columbus  13215.0\n",
       "4605     0.250000      8     Columbus, GA     Columbus  13215.0\n",
       "4606     0.250000      3     Columbus, GA     Columbus  13215.0\n",
       "4607     0.333333      9     Columbus, GA     Columbus  13215.0\n",
       "4608     0.250000      7     Columbus, GA     Columbus  13215.0\n",
       "4609     0.500000      3       Vernal, UT       Vernal  49047.0\n",
       "4610     2.000000      1       Vernal, UT       Vernal  49047.0\n",
       "4611     2.000000      4       Vernal, UT       Vernal  49047.0\n",
       "4612     0.500000     12     Lewiston, ID     Lewiston  16069.0\n",
       "4613     0.058824      7         Hilo, HI         Hilo  15001.0\n",
       "4614     0.066667     12         Hilo, HI         Hilo  15001.0\n",
       "4615     1.500000     12  Punta Gorda, FL  Punta Gorda  12015.0\n",
       "\n",
       "[4616 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Madison, WI\n",
      "1    Madison, WI\n",
      "2    Madison, WI\n",
      "3    Madison, WI\n",
      "4    Madison, WI\n",
      "Name: DEST_CITY_NAME, dtype: object\n",
      "1209    Aberdeen, SD\n",
      "1211    Aberdeen, SD\n",
      "1212    Aberdeen, SD\n",
      "1213    Aberdeen, SD\n",
      "1214    Aberdeen, SD\n",
      "Name: DEST_CITY_NAME, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'DEST_CITY_NAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9561a3d65024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflight_df_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflight_df_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mflight_df_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcities_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflight_df_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DEST_CITY_NAME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcities_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/elahe/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2428\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2429\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas/_libs/index.c:4363)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas/_libs/index.c:4046)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5169)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DEST_CITY_NAME'"
     ]
    }
   ],
   "source": [
    "\n",
    "flight_df_result=flight_df[\"DEST_CITY_NAME\"].dropna()\n",
    "print flight_df_result.head()\n",
    "flight_df_result=flight_df_result.sort_values()\n",
    "print flight_df_result.head()\n",
    "cities_list = flight_df_result[\"DEST_CITY_NAME\"].values\n",
    "cities = cities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
